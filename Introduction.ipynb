{
 "cells": [
  {
   "cell_type": "raw",
   "id": "5baa39e2-a075-4c64-b084-69a57b5797bb",
   "metadata": {
    "vscode": {
     "languageId": "raw"
    }
   },
   "source": [
    "---\n",
    "title: \"Introduction\"\n",
    "format:\n",
    "    html:\n",
    "jupyter: python3\n",
    "number-sections: true\n",
    "number-depth: 3\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a3fd25a4",
   "metadata": {},
   "source": [
    "In artifical intelligence (AI), an agent is broadly defined as anything that can perceive and act in its own environment [@norvig2002modern]. With the rise of large language models (LLMs), LLMs are now used to power modern agentic systems by leveraging the general intelligence capabilities of a LLM [@brown2020language]. At its best, a LLM can dynamically decide the sequence of steps that need to be executed in order to accomplish a given task, essentially achieving autonomy. \n",
    "\n",
    "In practice, agentic systems differ in the degree of reliance on the LLM as a decision maker, since the increased flexibility that LLMs provide also comes at the cost of reliability. On one end of the spectrum is a LLM workflow, which has LLMs participate in a limited scope within a broader predefined workflow. On the other end of the spectrum is a LLM agent, where the LLM directs its own workflow to accomplish a task. We can illustrate the difference between a workflow and an agent with a customer service chatbot example:\n",
    "\n",
    "+ **Workflow**: a potential workflow executes (1) intent classification by a LLM, (2) tool execution based on intent, and (3) LLM response generation. Based on the determined intent, only one tool is executed by following a pre-defined if-else control flow. \n",
    "+ **Agent**: given a set of tools, a LLM dynamically decides which tool to use in response to customer inquiry. In this process, multiple tools can be used any number of times, with the steps planned or decided by the LLM itself. Once the LLM determines it has collected sufficient information from tool-use to respond, it generates a final response to the customer.\n",
    "\n",
    "While an agent can tackle tasks more adaptively, it is also less predictable and reliable. On the other hand, workflows are more deterministic and thus more reliable, but they are limited in their ability to tackle more open-ended tasks where there may not be one obvious approach. Choosing between a workflow and an agent requires considering the balance of flexibility and reliability needed for the application. In the rest of this book, the word _agent_ will be used interchangeably with agentic systems, with the distinction between workflows and agents expliclty called out only when necessary. \n",
    "\n",
    "Building an agentic system from a LLM requires a prompt, tools, and memory. The prompt is piece of text that instructs the LLM on how to behave within the agent application. Tools allow an agent to take actions and is typically assessed by an agentic system in the form of an API. Finally, memory allows an agent to act and behave in a contextualized manner, with user information or conversation history being common memory contexts. Each of these components are the building blocks that can be used to create and shape a LLM agent. @fig-1 illustrates an agentic system and its components:\n",
    "\n",
    "![An agentic system and its components. Dotted and double-sided arrows indicate that the interaction is optional and bidirectional respectively. Additionally, the double-sideness implies that the interaction can be iterative, occuring multiple times until the LLM determines its task is done. Source: \"Building Effective Agents\" (https://www.anthropic.com/index/building-effective-agents).](./pics/llm_agent_system.png){#fig-1 fig-align=\"center\" width=100%}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bd83fff3",
   "metadata": {},
   "source": [
    "## Prompt\n",
    "\n",
    "A prompt is a piece of text that instructs a LLM how to behave within an agent application. A prompt can be organized conceptually into a system prompt, contextual prompt, role prompt, and a user prompt. In the end, they are all concatenated together into a single text input when invoking the LLM (i.e. asking LLM to generate repsonse). \n",
    "\n",
    "+ **System prompt**: contains high level instructions that should always be applied and thus is always part of the input text when invoking a LLM. Typically, the system prompt contains instructions asking the LLM to be a helpful and patient agent.\n",
    "+ **Role prompt**: in an agentic system, LLMs may be required to behave differently depending on the scenario. For example, in multi-agent collaboration where multiple specialized agents communicate together to solve as task, each specialized agent will need a role prompt. To implement this behavior, multiple role prompts are maintained and a specific role prompt is selected and concatenated with the remaining prompts depending on the scenario or role.\n",
    "+ **User prompt**: the question or instruction from the user of the agent application. The user prompt is typically appended to the end of the final prompt that is passed to the LLM.\n",
    "+ **Contextual prompt**: catch-all prompt for all contextual details needed for an agent to respond to a user request. For industry applications, this could be the account information of the user in the current conversation session. Having a contextual prompt is important for a good and safe user experience as it saves the user from having to state user information that might be later used by the agent.\n",
    "\n",
    "Come LLM inference time, the process of putting together the final prompt typically involves concatenating the system prompt, one of the role prompts, the contextual prompt with contextual values filled in, and the user input. Below is an example for a bank agent chatbot, using AWS bedrock to access a LLM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2f239f6f-114e-4f47-b2f5-5916da08afe7",
   "metadata": {
    "vscode": {
     "languageId": "raw"
    }
   },
   "outputs": [],
   "source": [
    "import boto3\n",
    "\n",
    "SYSTEM_PROMMPT = \"\"\"\n",
    "<instruction>\n",
    "You are a helpful agent for XYZ bank. You are ALWAYS patient, helpful, and always try to \n",
    "assist the user in the best way possible. \n",
    "</instruction>\n",
    "\"\"\"\n",
    "\n",
    "ROLE_PROMPT_REPORTING = \"\"\"\n",
    "You are tasked with account reporting. \n",
    "Use the following function to look up the account information:\n",
    "\n",
    "{\n",
    "    \"function_name\": \"account_lookup\",\n",
    "    \"description\": \"a tool to retrieve account information for a user.\",\n",
    "    \"arguments\": {\n",
    "        \"username\": {\"type\": str, \"description\": \"user name\"},\n",
    "        \"security_code\": {\"type\": str, \"description\": \"security code\"}\n",
    "    }\n",
    "}\n",
    "\n",
    "NEVER reveal account Ids.\n",
    "\"\"\"\n",
    "\n",
    "CONTEXTUAL_PROMPT = \"\"\"\n",
    "Use below account information <account> about the customer:\n",
    "\n",
    "<account>\n",
    "Username: {username}\n",
    "account_type: {account_type}\n",
    "</account>\n",
    "\"\"\"\n",
    "\n",
    "user_input = \"Can you get the ending balance of each month for 2024?\"\n",
    "bedrock_runtime = boto3.client(\"bedrock-runtime\", region_name=\"us-west-1\")\n",
    "bedrock_runtime_response = bedrock_runtime.converse(\n",
    "    modelId = \"us.anthropic.claude-3-7-sonnet-20250219-v1:0\",\n",
    "    system = [\n",
    "                {'text': SYSTEM_PROMMPT}, \n",
    "                {'text': ROLE_PROMPT_REPORTING}, \n",
    "                {'text': CONTEXTUAL_PROMPT.format(username = \"caleb\", \n",
    "                                                  account_type = \"savigns\")}\n",
    "    ],\n",
    "    messages = [{\"role\": \"user\", \"content\": [{\"text\": user_input}]}]\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a9dfd0b1-5037-4a3f-b80a-e480dda86044",
   "metadata": {},
   "source": [
    "According to Anthropic, using XML tags in your prompts can help Claude models parse specific components in your prompt more easily. For example, better identifying which part of the prompt is the system prompt by the `<instruction>` tag. As a heuristic, capitalize words for emphasis, such as the words \"NEVER\" or \"ALWAYS\". "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e7f5862b",
   "metadata": {},
   "source": [
    "## Tools\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0155e1a8",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "source": [
    "## Memory\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "74c68e3f-09d8-4129-8083-d656cd5f7b27",
   "metadata": {},
   "outputs": [],
   "source": [
    "def tool(city):\n",
    "    if city == \"New York\":\n",
    "        return \"The weather in New York is sunny.\"\n",
    "    elif city == \"Los Angeles\":\n",
    "        return \"The weather in Los Angeles is warm.\"\n",
    "    else:\n",
    "        return \"Weather information for this city is not available.\""
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
